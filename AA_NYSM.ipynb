{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "26d0d4f6-9caf-46a0-87df-2957f463380f",
   "metadata": {},
   "source": [
    "# Arctic Amplification and New York State Temperature Anomalies\n",
    "\n",
    "Temperature Anomalies using CFSR Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8795155c-076d-475f-ad66-f89576742a69",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac316a0-b05d-4266-ae03-b7ade23dcec8",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "Introductory paragraph here ... blah blah AA using CFSR Data, and NYS using NYSM w only 6 years..\n",
    "\n",
    "1. Section 1: Create Monthly Mean Datasets by Year from 1979-2022 using CFSR Data\n",
    "2. Section 2: Create Temperature Anomaly & Arctic Amplification Figures using CFSR Data\n",
    "3. Third Content Section"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8653f1da-ba44-416e-b28e-be3aff64ea29",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "Not sure if I want to add these"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee426420-f553-43f5-9e01-d88c2cca6f41",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "232e2256-f0bc-4dc0-b83e-4e1d57c43d3a",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1af3ba9-cde6-4bfa-bcf0-8d628d043ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime #remove for final version\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c35a6e-d05c-4a2a-a100-aec24ce53482",
   "metadata": {},
   "source": [
    "## Section 1: Create Monthly Mean Datasets by Year from 1979-2022 using CFSR Data\n",
    "\n",
    "This section is for ***Reference Only*** because the monthly mean computations take a long time to run at ~6 minutes per year (over 4 hours for the full 43 years of data). This code has already been ran and net cdf files have been saved out locally, so those files can be read in and used as pre-computed datasets for later parts of this notebook.\n",
    "\n",
    "Data source: Climate Forecast System Renanalysis, https://climatedataguide.ucar.edu/climate-data/climate-forecast-system-reanalysis-cfsr\n",
    "\n",
    "Local copies (/cfsr/data/) of CFSR datasets were used in this notebook.\n",
    "\n",
    "Referenced notebooks: UAlbany ATM622 Jupyter notebook https://brian-rose.github.io/general-circulation/lectures/computing-seasonal.html\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ed6123-a3b0-4d56-ba47-b48c5000790b",
   "metadata": {},
   "source": [
    "### Define functions\n",
    "Functions are used when creating and saving each monthly mean dataset by year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a4e55c6-7a9b-4f49-a2a2-4e6c65de179b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dir(path):\n",
    "    \"\"\" \n",
    "    Input directory path as string\n",
    "    Creates the directory if it doesn't already exist\n",
    "    \"\"\" \n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "        \n",
    "def open_ds(yr):\n",
    "    \"\"\" Open dataset using dask \"\"\"\n",
    "    ds = xr.open_mfdataset(f'/cfsr/data/{yr}/{var}.{yr}.0p5.anl.nc', chunks={'time':30*4, 'lev': 4}, parallel=True) # removed this before /cfsr \"/network/daes\"\n",
    "    return ds\n",
    "\n",
    "def compute_save_means(ds_for_mean, yr):\n",
    "    \n",
    "    \"\"\" \n",
    "    Input dataset based depends on whether grouping seasonally, annually, etc.\n",
    "    Perform lazy execution averaging on the input dataset\n",
    "    Calculation is executed when saving to path\n",
    "    \"\"\"\n",
    "    ds_mean = ds_for_mean.mean(dim=('lon','time'), skipna=True)\n",
    "    save_path = f'{save_dir}/{group_desc}_{var}_{yr}.nc'\n",
    "    ds_mean.to_netcdf(save_path)\n",
    "    print(save_path) #comment out for final version\n",
    "    print(f\"finished {yr} at {datetime.datetime.now()}\") #comment out for final version\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d9d68ca-5fe5-4503-bc25-51de53248f3e",
   "metadata": {},
   "source": [
    "### Create and save monthly mean temperature datasets for each year from 1979-2022"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc49076e-0e23-4ef3-be50-2989817faf54",
   "metadata": {},
   "source": [
    "#### Define Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff30c4c7-d4a1-476c-93ca-60a01032e41e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define CFSR variable of interest (e.g. temperature is 't') \n",
    "var = 't' \n",
    "\n",
    "# Describes how data should be grouped for averaging, used in file and directory names\n",
    "group_desc = 'monthly' \n",
    "\n",
    "# Directory where averaged net cdf files will be saved out\n",
    "save_dir = f'/home11/grad/2021/cs436778/general-circulation/project/data/{group_desc}'\n",
    "\n",
    "# Years of CFSR data to include; each will be looped over\n",
    "years = range(1979, 2023)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f978e7e4-c5e4-4502-be05-89f45b285081",
   "metadata": {},
   "source": [
    "#### Execute monthly mean calculation for each year and save dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10458ae4-3e62-40a2-8bc4-5d339187c4c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# execute function monthl\n",
    "\n",
    "make_dir(save_dir)\n",
    "\n",
    "for year in years:\n",
    "\n",
    "    ds = open_ds(year)\n",
    "\n",
    "    # group dataframe depending on seasonal, annual, monthly means\n",
    "    ds_grouped = ds.groupby(ds.time.dt.month)\n",
    "\n",
    "    compute_save_means(ds_grouped, year)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f1d772-6c5f-4dff-895c-7c770edfb3d1",
   "metadata": {},
   "source": [
    "## Section 2: Create Temperature Anomaly & Arctic Amplification Figures using CFSR Data\n",
    "\n",
    "Recreate figures 1A and 2A from **Francis & Vavrus 2015**. Citation and link to paper: Jennifer A Francis and Stephen J Vavrus 2015 Environ. Res. Lett. 10 014005,  https://iopscience.iop.org/article/10.1088/1748-9326/10/1/014005#erl507077bib8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bff046f-42ac-4df0-88e9-2ebe79417883",
   "metadata": {},
   "source": [
    "### Read in pre-computed monthly mean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f805b469-e866-40f2-8683-3a7e556f4350",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parent dir where annual temp data lives\n",
    "# dir_seasonal_t = '/home11/grad/2021/cs436778/general-circulation/project/data/seasonal/'\n",
    "dir_annual_t = '/home11/grad/2021/cs436778/general-circulation/project/data/annual/'\n",
    "dir_monthly_t = '/home11/grad/2021/cs436778/general-circulation/project/data/monthly/'\n",
    "\n",
    "# Define the years of data to read in. As discussed above, we will read in 2002 through 2021\n",
    "years = range(1979,2022)\n",
    "\n",
    "leap = ['1980', '1984', '1988', '1992', '1996', '2000', '2004', '2008', '2012', '2016', '2020']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ffaefce-a7f0-4548-bf70-ed9b9afa68bb",
   "metadata": {},
   "source": [
    "### Calculate Annual and Seasonal long-term averages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b10347b9-9333-4e92-8e82-7b584e314c01",
   "metadata": {},
   "source": [
    "#### Define Functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65506d09-acfb-4df2-8e4a-0864d275a26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def latrange_mean(dataset, elev_p, latrange):\n",
    "    \"\"\" \n",
    "    For each year, read in the seasonal dataset and subset by elevation and latitude range (ex: arctic and mid latitudes)\n",
    "    Calculate the latitude-weighted mean temperature for each season\n",
    "    \"\"\"\n",
    "    latrange = dataset.t.sel(lev=elev_p, lat = latrange)\n",
    "    latrange_weights = np.cos(np.deg2rad(latrange.lat))\n",
    "    latrange_mean = latrange.weighted(latrange_weights).mean(dim = 'lat')\n",
    "    return latrange_mean\n",
    "\n",
    "def add_to_dict(dict_name, key_name, val):\n",
    "    \"\"\" Append a value to a key in a dictionary if the key already exists\n",
    "    Otherwise, if key doesnâ€™t exist in dict yet, add a new key and its value to the dictionary \n",
    "    \"\"\"\n",
    "    if key_name in dict_name:\n",
    "        if type(dict_name[key_name]) is not list:\n",
    "            key_current_val = [dict_name[key_name]]\n",
    "        else:\n",
    "            key_current_val = dict_name[key_name]\n",
    "        key_current_val.append(val)\n",
    "        dict_name[key_name] = key_current_val\n",
    "    else:\n",
    "        dict_name[key_name] = val    \n",
    "        \n",
    "def yearly_monthly_means(dataset, dict_name):\n",
    "    \"\"\"\n",
    "    For each season, track the year, season, and mean value (three keys)\n",
    "    Returns a dictionary of the tracked data \n",
    "    \"\"\"\n",
    "    for month_num in range(1,13):\n",
    "        month_val = dataset.sel(month = month_num).values.item()\n",
    "        add_to_dict(dict_name, month_num, month_val)\n",
    "        \n",
    "def year_month_length(yr, dictname):\n",
    "    \"\"\"\n",
    "    Identifies the length of day in a month or year depending on leap year\n",
    "    Note: These lengths will be used for calculating seasonal and annual climatologies rather than using xarray's built in averaging over 'time.season' which is DJF rather than JFM\n",
    "    \"\"\"\n",
    "    if yr in leap:\n",
    "        add_to_dict(dictname, 'count_2', 29)\n",
    "        add_to_dict(dictname, 'count_year', 366)\n",
    "    else: \n",
    "        add_to_dict(dictname, 'count_2', 28)\n",
    "        add_to_dict(dictname, 'count_year', 365)\n",
    "    add_to_dict(dictname, 'count_1', 31)\n",
    "    add_to_dict(dictname, 'count_3', 31)\n",
    "    add_to_dict(dictname, 'count_4', 30)\n",
    "    add_to_dict(dictname, 'count_5', 31)\n",
    "    add_to_dict(dictname, 'count_6', 30)\n",
    "    add_to_dict(dictname, 'count_7', 31)\n",
    "    add_to_dict(dictname, 'count_8', 31)\n",
    "    add_to_dict(dictname, 'count_9', 30)\n",
    "    add_to_dict(dictname, 'count_10', 31)\n",
    "    add_to_dict(dictname, 'count_11', 30)\n",
    "    add_to_dict(dictname, 'count_12', 31)\n",
    "\n",
    "# Create dictionaries of data by month and year for a given latitude range and pressure level\n",
    "def dict_month_data(plevel, lat_low, lat_high):\n",
    "    new_dict = {}\n",
    "    for year in range(1979,2022):\n",
    "        \n",
    "        # add year to dictionary\n",
    "        year = str(year)\n",
    "        add_to_dict(new_dict, 'year_name', year)\n",
    "        \n",
    "        # open datasets\n",
    "        ds_year_month = xr.open_mfdataset(f\"{dir_monthly_t}monthly_t_{year}.nc\")\n",
    "        ds_year = xr.open_mfdataset(f\"{dir_annual_t}annual_t_{year}.nc\")\n",
    "\n",
    "        # subset datasets\n",
    "        lat_avg_months = latrange_mean(ds_year_month, plevel, slice(lat_low,lat_high))\n",
    "        lat_avg_year = latrange_mean(ds_year, plevel, slice(lat_low,lat_high))\n",
    "        \n",
    "        # add subsetted data to dictionary\n",
    "        yearly_monthly_means(lat_avg_months, new_dict)\n",
    "        add_to_dict(new_dict, 'annual', lat_avg_year.values.item())\n",
    "        \n",
    "        # add month length and year length to dictionary accounting for leap years\n",
    "        year_month_length(year, new_dict)\n",
    "            \n",
    "    return new_dict\n",
    "\n",
    "# calculate seasonaly and annual climatologies, used for calculating anomalous temp\n",
    "def seasonal_climatology(region_dict, months_ls):\n",
    "    \"\"\" \n",
    "    Input regional dictionary of temps by month (e.g. arctic_dict made above) \n",
    "    Input list of month numbers that should be averaged to create season (e.g. input list [1,2,3] to average Jan, Feb, Mar)\n",
    "    Returns average value for season \n",
    "    \"\"\"\n",
    "    month_values = region_dict[months_ls[0]] + region_dict[months_ls[1]] + region_dict[months_ls[2]]\n",
    "    month_weights = region_dict[f\"count_{str(months_ls[0])}\"] + region_dict[f\"count_{str(months_ls[1])}\"] + region_dict[f\"count_{str(months_ls[2])}\"]\n",
    "    season_mean = np.average(month_values, weights = month_weights)\n",
    "    return season_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1356149-dc4c-4765-986a-95c94ebd0b77",
   "metadata": {},
   "source": [
    "#### Create dictionaries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c2bec508-100d-4685-b2c7-21af7cb8c9f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "midlat_dict_new = dict_month_data(1000, 30, 60)\n",
    "arctic_dict_new = dict_month_data(1000, 70, 90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa662de-6cf7-4715-9b87-6a0219a01436",
   "metadata": {},
   "outputs": [],
   "source": [
    "arctic_dict_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0770753c-495c-40b2-a157-1ed5b4edc192",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['year_name', 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 'annual', 'count_2', 'count_year', 'count_1', 'count_3', 'count_4', 'count_5', 'count_6', 'count_7', 'count_8', 'count_9', 'count_10', 'count_11', 'count_12'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arctic_dict_new.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "48d0fd6e-d017-46f1-9486-2c7ee65fa7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # create dictionaries which averages will be appended to\n",
    "# midlat_dict = {}\n",
    "# arctic_dict = {}\n",
    "\n",
    "# # Add seasonal data for each year from 1979-2021 \n",
    "# for year in range(1979,2022):\n",
    "#     \"\"\" \n",
    "#     Open dataset for each year\n",
    "#     \"\"\"\n",
    "#     year = str(year)\n",
    "    \n",
    "#     # add year\n",
    "#     add_to_dict(midlat_dict, 'year_name', year)\n",
    "#     add_to_dict(arctic_dict, 'year_name', year)\n",
    "                  \n",
    "#     # open dataset\n",
    "#     ds_year = xr.open_mfdataset(f\"{dir_annual_t}annual_t_{year}.nc\")\n",
    "#     ds_year_month = xr.open_mfdataset(f\"{dir_monthly_t}monthly_t_{year}.nc\")\n",
    "\n",
    "#     # middle latitudes - annual\n",
    "#     midlat_mean_year = latrange_mean(ds_year, 1000, slice(30,60))\n",
    "#     add_to_dict(midlat_dict, 'annual', midlat_mean_year.values.item())\n",
    "#     # middle latitudes - seasonal\n",
    "#     midlat_mean_month = latrange_mean(ds_year_month, 1000, slice(30,60))\n",
    "#     yearly_monthly_means(midlat_mean_month, midlat_dict)\n",
    "\n",
    "#     # arctic - annual\n",
    "#     arctic_mean_year = latrange_mean(ds_year, 1000, slice(70,90))\n",
    "#     add_to_dict(arctic_dict, 'annual', arctic_mean_year.values.item())\n",
    "#     # arctic - seasonal\n",
    "#     arctic_mean_month = latrange_mean(ds_year_month, 1000, slice(70,90))\n",
    "#     yearly_monthly_means(arctic_mean_month, arctic_dict)\n",
    "    \n",
    "#     # add fields for ct_feb and ct_yr depending if leap year. Used in averaging\n",
    "#     year_month_length(year)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8aff7143-1f02-4f26-bfec-7186bc36ad39",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "arctic_jfm_mean = seasonal_climatology(arctic_dict_new, [1,2,3])\n",
    "midlat_jfm_mean = seasonal_climatology(midlat_dict_new, [1,2,3])\n",
    "\n",
    "arctic_amj_mean = seasonal_climatology(arctic_dict_new, [4,5,6])\n",
    "midlat_amj_mean = seasonal_climatology(midlat_dict_new, [4,5,6])\n",
    "\n",
    "arctic_jas_mean = seasonal_climatology(arctic_dict_new, [7,8,9])\n",
    "midlat_jas_mean = seasonal_climatology(midlat_dict_new, [7,8,9])\n",
    "\n",
    "arctic_ond_mean = seasonal_climatology(arctic_dict_new, [10,11,12])\n",
    "midlat_ond_mean = seasonal_climatology(midlat_dict_new, [10,11,12])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc861ac-38b9-4134-b0fc-bc9ba73adea5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6317398a-da31-4b59-b7a3-474f32a062c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# seasonally\n",
    "arctic_jfm_tomean = arctic_dict_new[1] + arctic_dict_new[2] + arctic_dict_new[3]\n",
    "arctic_jfm_weights = arctic_dict_new['count_1'] + arctic_dict_new['count_2'] + arctic_dict_new['count_3']\n",
    "arctic_jfm= np.average(arctic_jfm_tomean, weights = arctic_jfm_weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ec2dc4e3-2baa-4499-a7ff-e6942b70541b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "252.0783331934185"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arctic_jfm_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6db0585f-4298-45d0-8b08-fcd5d8c9f833",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Axis must be specified when shapes of a and weights differ.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [27]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m arctic_jfm_tomean \u001b[38;5;241m=\u001b[39m arctic_dict[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m+\u001b[39m arctic_dict[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m+\u001b[39m arctic_dict[\u001b[38;5;241m3\u001b[39m]\n\u001b[1;32m      5\u001b[0m arctic_jfm_weights \u001b[38;5;241m=\u001b[39m arctic_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mc1\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m arctic_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mc2\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m arctic_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mc3\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m----> 6\u001b[0m arctic_jfm\u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maverage\u001b[49m\u001b[43m(\u001b[49m\u001b[43marctic_jfm_tomean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43marctic_jfm_weights\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36maverage\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m/knight/anaconda_aug22/envs/aug22_env/lib/python3.10/site-packages/numpy/lib/function_base.py:508\u001b[0m, in \u001b[0;36maverage\u001b[0;34m(a, axis, weights, returned)\u001b[0m\n\u001b[1;32m    506\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m a\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m!=\u001b[39m wgt\u001b[38;5;241m.\u001b[39mshape:\n\u001b[1;32m    507\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 508\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    509\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAxis must be specified when shapes of a and weights \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    510\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdiffer.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    511\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m wgt\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    512\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    513\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1D weights expected when shapes of a and weights differ.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: Axis must be specified when shapes of a and weights differ."
     ]
    }
   ],
   "source": [
    "# calculate averages from monthly data (average across years) - need this for relative for anom calc\n",
    "\n",
    "# seasonally\n",
    "arctic_jfm_tomean = arctic_dict[1] + arctic_dict[2] + arctic_dict[3]\n",
    "arctic_jfm_weights = arctic_dict['c1'] + arctic_dict['c2'] + arctic_dict['c3']\n",
    "arctic_jfm= np.average(arctic_jfm_tomean, weights = arctic_jfm_weights)\n",
    "\n",
    "# arctic_amj_tomean = arctic_dict[4] + arctic_dict[5] + arctic_dict[6]\n",
    "# arctic_amj_weights = arctic_dict['c4'] + arctic_dict['c5'] + arctic_dict['c6']\n",
    "# arctic_amj= np.average(arctic_amj_tomean, weights = arctic_amj_weights)\n",
    "\n",
    "# arctic_jas_tomean = arctic_dict[7] + arctic_dict[8] + arctic_dict[9]\n",
    "# arctic_jas_weights = arctic_dict['c7'] + arctic_dict['c8'] + arctic_dict['c9']\n",
    "# arctic_jas= np.average(arctic_jas_tomean, weights = arctic_jas_weights)\n",
    "\n",
    "# arctic_ond_tomean = arctic_dict[10] + arctic_dict[11] + arctic_dict[12]\n",
    "# arctic_ond_weights = arctic_dict['c10'] + arctic_dict['c11'] + arctic_dict['c12']\n",
    "# arctic_ond= np.average(arctic_ond_tomean, weights = arctic_ond_weights)\n",
    "\n",
    "# midlat_jfm_tomean = midlat_dict[1] + midlat_dict[2] + midlat_dict[3]\n",
    "# midlat_jfm_weights = midlat_dict['c1'] + midlat_dict['c2'] + midlat_dict['c3']\n",
    "# midlat_jfm= np.average(midlat_jfm_tomean, weights = midlat_jfm_weights)\n",
    "\n",
    "# midlat_amj_tomean = midlat_dict[4] + midlat_dict[5] + midlat_dict[6]\n",
    "# midlat_amj_weights = midlat_dict['c4'] + midlat_dict['c5'] + midlat_dict['c6']\n",
    "# midlat_amj= np.average(midlat_amj_tomean, weights = midlat_amj_weights)\n",
    "\n",
    "# midlat_jas_tomean = midlat_dict[7] + midlat_dict[8] + midlat_dict[9]\n",
    "# midlat_jas_weights = midlat_dict['c7'] + midlat_dict['c8'] + midlat_dict['c9']\n",
    "# midlat_jas= np.average(midlat_jas_tomean, weights = midlat_jas_weights)\n",
    "\n",
    "# midlat_ond_tomean = midlat_dict[10] + midlat_dict[11] + midlat_dict[12]\n",
    "# midlat_ond_weights = midlat_dict['c10'] + midlat_dict['c11'] + midlat_dict['c12']\n",
    "# midlat_ond= np.average(midlat_ond_tomean, weights = midlat_ond_weights)\n",
    "\n",
    "# # yearly\n",
    "# arctic_ann_tomean = arctic_jfm_tomean+arctic_amj_tomean+arctic_jas_tomean+arctic_ond_tomean\n",
    "# arctic_ann_weights = arctic_jfm_weights+arctic_amj_weights+arctic_jas_weights+arctic_ond_weights\n",
    "# arctic_ann= np.average(arctic_ann_tomean, weights = arctic_ann_weights)\n",
    "\n",
    "# midlat_ann_tomean = midlat_jfm_tomean+midlat_amj_tomean+midlat_jas_tomean+midlat_ond_tomean\n",
    "# midlat_ann_weights = midlat_jfm_weights+midlat_amj_weights+midlat_jas_weights+midlat_ond_weights\n",
    "# midlat_ann= np.average(midlat_ann_tomean, weights = midlat_ann_weights)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfca4df3-a3e9-4fd0-9d96-87484dad6fb5",
   "metadata": {},
   "source": [
    "### Plot annual-mean anomalies in air temperature (Francis & Vavrus 2015) Plot 1A\n",
    "\n",
    "Plot 1: Annual-mean anomalies in air temperature for 40â€“80Â°N (recreating figure 1a from Francis & Vavrus)\n",
    "- \"Annual anomaly\" is defined as the difference in annual mean relative to the **1989-2018 mean** (30 years)\n",
    "    - Note that this is updated from Francis & Vavrus' available data from 1981â€“2010 (30 years)\n",
    "- Anomalies in air temperature are calculated for each year from **2003 through 2021** (19 years) and averaged to get annual-mean anomalies which are plotted by latitude and elevation. \n",
    "    - Note that this is updated from Francis & Vavrus' anomalies calculatued for 1995 through 2013 (19 years).\n",
    "- Thus, all data ranges have been shifted forward 8 years"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d93e9080-b3b2-4659-95e3-0d1915ccfabb",
   "metadata": {},
   "source": [
    "### Plot 2A\n",
    "\n",
    " Arctic amplification seasonal time series\n",
    "- Arctic Amplification defined as the difference in 1000 hPa temperature anomalies (relative to 1979â€“2021 mean), between the Arctic (70â€“90Â°N) and mid-latitudes (30â€“60Â°N)\n",
    "    - Note that this is updated from Francis & Vavrus' available data from 1948â€“2013 mean\n",
    "\n",
    "- Q: need seasonal climatologies or just the seasonal means by year?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "373b6427-2127-4018-9a33-567c450d3379",
   "metadata": {},
   "source": [
    "## Third Content Section"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a711ab4-0792-45c2-a83c-f8f0ba211ddb",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64a69e7d-0dd0-4588-9f39-dcb9939d9c97",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Paragraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce8cece3-4a17-4034-b5d3-054e2606a0f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 August 2022 Environment",
   "language": "python",
   "name": "aug22"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
